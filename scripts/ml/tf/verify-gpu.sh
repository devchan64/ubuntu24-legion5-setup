#!/usr/bin/env bash
# GPU/Ïª®ÌÖåÏù¥ÎÑà Ìò∏Ìôò Ïä§Î™®ÌÅ¨ ÌÖåÏä§Ìä∏
# - NVIDIA ÎìúÎùºÏù¥Î≤Ñ (nvidia-smi)
# - Docker Îü∞ÌÉÄÏûÑ
# - CUDA Î≤†Ïù¥Ïä§ Ïª®ÌÖåÏù¥ÎÑàÏóêÏÑú nvidia-smi
# - TensorFlow GPU Ïª®ÌÖåÏù¥ÎÑàÏóêÏÑú Python GPU Í∞ÄÏö©ÏÑ± Ï≤¥ÌÅ¨
# Ï†ïÏ±Ö: Ìè¥Î∞± ÏóÜÏùå, Ïã§Ìå® Ï¶âÏãú Ï§ëÎã®
set -Eeuo pipefail

. "$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")/../../.." >/dev/null 2>&1 && pwd -P)/lib/common.sh"

require_cmd docker
command -v nvidia-smi >/dev/null 2>&1 || err "nvidia-smi not found. NVIDIA ÎìúÎùºÏù¥Î≤ÑÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§."

CUDA_IMAGE="${CUDA_IMAGE:-nvidia/cuda:12.4.1-base-ubuntu22.04}"
TF_IMAGE="${TF_IMAGE:-tensorflow/tensorflow:latest-gpu-jupyter}"

log "‚õè  Host NVIDIA driver:"
nvidia-smi || err "nvidia-smi failed"

log "‚õè  Docker version:"
docker --version || err "docker not working"

log "üê≥ Pull CUDA image: ${CUDA_IMAGE}"
docker pull "${CUDA_IMAGE}"

log "‚ñ∂  Run nvidia-smi inside CUDA image"
docker run --rm --gpus all "${CUDA_IMAGE}" nvidia-smi >/dev/null \
  || err "CUDA container failed to access GPU"

log "üê≥ Pull TF image: ${TF_IMAGE}"
docker pull "${TF_IMAGE}"

log "‚ñ∂  TensorFlow GPU availability check"
docker run --rm --gpus all "${TF_IMAGE}" python - <<'PY'
import sys
try:
    import tensorflow as tf
    gpus = tf.config.list_physical_devices("GPU")
    if not gpus:
        print("[ERROR] No GPU visible to TensorFlow", file=sys.stderr)
        sys.exit(2)
    print("[OK] GPUs:", [d.name for d in gpus])
    sys.exit(0)
except Exception as e:
    print("[ERROR] TF import or check failed:", e, file=sys.stderr)
    sys.exit(3)
PY

log "[OK] GPU/Container smoke test passed."
